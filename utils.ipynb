{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "## Overview\n",
    "This notebook contains utility functions used prior to the implementation of the U-Net. All functions contain doc strings which define the function inputs and outputs, and their data types. There are also comments throughout each function for additional clarity.\n",
    "\n",
    "## Structure\n",
    "- **[Import Necessary Packages](#import-necessary-packages)**: Importing the necessary packages used by functions in this notebook.\n",
    "- **[Internal Functions](#internal-functions)**: Internal or private functions that are only called by other functions and should never be called directly by a script. \n",
    "    - [`_display_samples`]: Function to plot the given data, whether images or masks.\n",
    "- **[Public Functions](#public-functions)**: Public functions to be imported and called by other scripts, outside of this notebook. \n",
    "    - [`custom_warnings`](#custom-warnings): Function to format warnings in the desired manner\n",
    "    - [`load_images_and_masks`](#load-images-and-masks): Function to load images and masks from their given directories.\n",
    "    - [`remap_mask_classes`](#remap-mask-classes): Function to remap mask classes to a subset of the classes. \n",
    "    - [`view_data`](#view-data): Function to view images and/or masks. Calls [`_display_samples`](#display-samples).\n",
    "    - [`preprocess_images_and_masks`](#preprocess-images-and-masks): Function to preprocess and format the data for the U-Net.\n",
    "    - [`save_datasets`](#save-datasets): Function to save pre-split datasets into individual training, test, and validation `.npy` files.\n",
    "    - [`load_datasets`](#load-datasets): Function to load in the pre-split datasets, saved by [`save_datasets`](#save-datasets).\n",
    "    -  [`save_associated_files`](#save_associated_files): Function to copy exisitng files and save them to another folder. This function is generally intended for use with predicted masks, and associated files that contain geospatial information for the original masks\n",
    "\n",
    "\n",
    "## Usage\n",
    "This notebook is not intended to be run individually. The public functions in this notebook should be imported into the `main.ipynb` using the `import-ipynb` package. The purpose of this notebook is to clearly separate and define each utility function that is called internally (in this notebook by one of the other functions) and each utility function that is called in `main.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages\n",
    "\n",
    "We first import the necessary packages used by the functions in this notebook. These libraries should already be installed using the [`requirements.txt`](requirements.txt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict, List, Tuple, Any, TextIO\n",
    "\n",
    "# Optional line to suppress unnecessary tensorflow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Functions\n",
    "\n",
    "This section contains any internal, or private functions. These functions are ones that are called by other functions, and are not intended for use in any other manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Samples\n",
    "\n",
    "The function `_display_samples` is called in [View Data](#view-data). This function takes in a give set of samples, either images or masks, and then plots them in the desired format. This function is separated out as an internal function because it is called multiple times in [View Data](#view-data), and it is better practice to create a separate function for repeated code.\n",
    "\n",
    "\n",
    "#### _display_samples\n",
    "```\n",
    "def _display_samples(\n",
    "    samples: Dict[str, Any],\n",
    "    sample_names: List[str],\n",
    "    sample_type: int,\n",
    "    max_cols: int,\n",
    "    max_plots: int,\n",
    "    colors: bool,\n",
    "    scale: float = 1,\n",
    ") -> None:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Displays the samples by plotting them.\n",
    "\n",
    "#### Parameters\n",
    "- `samples` (Dict[str, Any]): \n",
    "\n",
    "    Dictionary containing the samples. Keys are sample names.\n",
    "\n",
    "- `sample_names` (List[str]): \n",
    "\n",
    "    List of sample names.\n",
    "\n",
    "- `sample_type` (int): \n",
    "\n",
    "    Type of sample, either 1 (masks) or 0 (images).\n",
    "\n",
    "- `max_cols` (int): \n",
    "\n",
    "    Maximum number of columns in the figure.\n",
    "\n",
    "- `max_plots` (int): \n",
    "\n",
    "    Maximum number of plots to display.\n",
    "\n",
    "- `colors` (bool): \n",
    "\n",
    "    Whether to use colors in the plots.\n",
    "\n",
    "- `scale` (float, optional): \n",
    "\n",
    "    Scale factor for the plot size. Default is 1.\n",
    "\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "samples = {\n",
    "    \"sample1\": np.random.rand(10, 10),\n",
    "    \"sample2\": np.random.rand(10, 10),\n",
    "    \"sample3\": np.random.rand(10, 10),\n",
    "    \"sample4\": np.random.rand(10, 10)\n",
    "}\n",
    "sample_names = [\"sample1\", \"sample2\", \"sample3\"]\n",
    "sample_type = 1  # Mask type\n",
    "max_cols = 2\n",
    "max_plots = 3\n",
    "colors = True\n",
    "scale = 1.5\n",
    "\n",
    "# Display the samples\n",
    "_display_samples(samples, sample_names, sample_type, max_cols, max_plots, colors, scale)\n",
    "```\n",
    "#### Notes\n",
    "- The function determines the number of columns and rows needed for the plots based on max_cols and max_plots.\n",
    "- It creates a figure and a grid of subplots using matplotlib.\n",
    "- The function chooses the color map based on the colors flag. If colors is True, it uses the \"viridis\" color map; otherwise, it uses the \"grey\" color map.\n",
    "- The function sets the title of the figure to \"Masks\" if sample_type is 1; otherwise, it sets the title to \"Images\".\n",
    "- For each sample, the function plots the sample in the correct subplot, using color or greyscale based on the colors flag.\n",
    "- The function removes any unused axes and adjusts the layout to prevent overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function used by view_data to actually display the figures for a given set of image or mask data. \n",
    "def _display_samples(\n",
    "    samples: Dict[str, Any],\n",
    "    sample_names: List[str],\n",
    "    sample_type: int,\n",
    "    max_cols: int,\n",
    "    max_plots: int,\n",
    "    colors: bool,\n",
    "    scale: float = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Displays the samples by plotting them.\n",
    "\n",
    "    Args:\n",
    "        samples (Dict[str, Any]): Dictionary containing the samples. Keys are sample names.\n",
    "        sample_names (List[str]): List of sample names.\n",
    "        sample_type (int): Type of sample, either 1 or 0.\n",
    "        max_cols (int): Maximum number of columns in the plot.\n",
    "        max_plots (int): Maximum number of plots to display.\n",
    "        colors (bool): Whether to use colors in the plots.\n",
    "        scale (float, optional): Scale factor for the plot size. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything. It displays the plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the number of columns and rows needed for the plots\n",
    "    num_cols = min(max_cols, max_plots)\n",
    "    num_rows = (max_plots + max_cols - 1) // max_cols\n",
    "\n",
    "    # Create a figure and a grid of subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        num_rows, num_cols, figsize=(num_cols * scale, num_rows * scale)\n",
    "    )\n",
    "    axes = np.array(axes).reshape(-1) # Flatten the axes array for easier iteration\n",
    "\n",
    "    # Choose the color map based on the 'colors' flag\n",
    "    if colors:\n",
    "        cmap = \"viridis\"\n",
    "        if sample_type == 1:\n",
    "            # Since the sample_type is 1 our samples are masks \n",
    "            fig.suptitle(\"Masks\")\n",
    "\n",
    "            # For each mask, scale the values based on the value range so that it may be plotted in color. Then plot the mask in the correct subplot\n",
    "            for idx, sample in enumerate(sample_names):\n",
    "                max_value = samples[sample].max() if samples[sample].max() else 1 # Set the max_value to 1 if it is 0, to prevent division by 0\n",
    "                axes[idx].imshow(samples[sample] / max_value, cmap=cmap)\n",
    "                axes[idx].set_title(f\"{sample}\")\n",
    "                axes[idx].axis(\"off\")\n",
    "        else:\n",
    "            # Since the sample_type is not 1 our samples are images \n",
    "            fig.suptitle(\"Images\")\n",
    "\n",
    "            # For each image, plot the image in color, in the correct subplot\n",
    "            for idx, sample in enumerate(sample_names):\n",
    "                axes[idx].imshow(samples[sample], cmap=cmap)\n",
    "                axes[idx].set_title(f\"{sample}\")\n",
    "                axes[idx].axis(\"off\")\n",
    "\n",
    "    else:\n",
    "        cmap = \"grey\"\n",
    "        # If the sample_type is 1 we have masks, otherwise we have images as our samples\n",
    "        fig.suptitle(\"Masks\") if sample_type == 1 else fig.suptitle(\"Images\")\n",
    "\n",
    "        # For each sample (image or mask), plot the sample in greyscale in the correct subplot.\n",
    "        for idx, sample in enumerate(sample_names):\n",
    "            axes[idx].imshow(samples[sample], cmap=cmap)\n",
    "            axes[idx].set_title(f\"{sample}\")\n",
    "            axes[idx].axis(\"off\")\n",
    "\n",
    "    # Remove any unused axes\n",
    "    for empty_idx in range(idx + 1, len(axes)):\n",
    "        fig.delaxes(axes[empty_idx])\n",
    "\n",
    "    # Adjust layout to prevent overlap and display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Functions\n",
    "\n",
    "The functions in this section are public functions which can be called or passed outside this notebook, and are intended for use in the `main.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Warnings\n",
    "The `custom_warnings` function is technically a public function, that is passed in `main.ipynb` to python's built in `warnings` library to tell it how we'd like our warnings displayed. However, we never actually **call** the function. **This function is deceptive, in it's use.** In `main.ipynb` the function itself is **passed** to `warnings` instead of **called**. It is also deceptive in that only the `category` and `message` inputs are explicitly used in our `custom_warnings` function. The remaining required inputs (`filename`, `lineno`) are required by the `warnings` library when formatting warning displays. You can find more details [here](https://docs.python.org/3/library/warnings.html#warnings.formatwarning).\n",
    "\n",
    "\n",
    "#### custom_warnings\n",
    "```\n",
    "def custom_warnings(\n",
    "    message: str,\n",
    "    category: type,\n",
    "    filename: str,\n",
    "    lineno: int,\n",
    "    file: Optional[TextIO] = None,\n",
    "    line: Optional[str] = None,\n",
    ") -> str:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Custom warning formatter.\n",
    "\n",
    "#### Parameters\n",
    "- `message` (str): \n",
    "\n",
    "    The warning message.\n",
    "\n",
    "- `category` (type): \n",
    "\n",
    "    The category of the warning.\n",
    "\n",
    "- `filename` (str): \n",
    "\n",
    "    The name of the file where the warning was raised.\n",
    "\n",
    "- `lineno` (int): \n",
    "\n",
    "    The line number where the warning was raised.\n",
    "\n",
    "- `file` (Optional[TextIO], optional): \n",
    "\n",
    "    The file object to write the warning to. Default is None.\n",
    "\n",
    "- `line` (Optional[str], optional): \n",
    "\n",
    "    The line of code where the warning was raised. Default is None.\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- `str`: \n",
    "    The formatted warning message.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import warnings\n",
    "\n",
    "# Define the custom warning display function\n",
    "def custom_warnings(\n",
    "    message: str,\n",
    "    category: type,\n",
    "    filename: str,\n",
    "    lineno: int,\n",
    "    file: Optional[TextIO] = None,\n",
    "    line: Optional[str] = None,\n",
    ") -> str:\n",
    "    return f\"{category.__name__}: {message}\\n\"\n",
    "\n",
    "# Set the custom warning display function\n",
    "warnings.formatwarning = custom_warnings\n",
    "\n",
    "# Trigger a warning to see the custom format\n",
    "warnings.warn(\"This is a custom warning message\", UserWarning)\n",
    "```\n",
    "#### Notes\n",
    "- The function formats the warning message by including the category name and the message.\n",
    "- The formatted message is returned as a string.\n",
    "- This function can be set as the warning formatter using `warnings.formatwarning = custom_warnings`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the custom warning display\n",
    "def custom_warnings(\n",
    "    message: str,\n",
    "    category: type,\n",
    "    filename: str,\n",
    "    lineno: int,\n",
    "    file: Optional[TextIO] = None,\n",
    "    line: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Custom warning formatter.\n",
    "\n",
    "    Args:\n",
    "        message (str): The warning message.\n",
    "        category (type): The category of the warning.\n",
    "        filename (str): The name of the file where the warning was raised.\n",
    "        lineno (int): The line number where the warning was raised.\n",
    "        file (Optional[TextIO], optional): The file object to write the warning to. Default is None.\n",
    "        line (Optional[str], optional): The line of code where the warning was raised. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted warning message.\n",
    "    \"\"\"\n",
    "    return f\"{category.__name__}: {message}\\n\" # Return the warning name, and the message of the warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images and Masks\n",
    "\n",
    "The `load_images_and_masks` function is a public function, that is called in `main.ipynb` to load in the images and masks from their respective directories. \n",
    "\n",
    "\n",
    "#### load_images_and_masks\n",
    "```\n",
    "def load_images_and_masks(\n",
    "    images_dir: str,\n",
    "    masks_dir: str,\n",
    "    file_ext: str = \"tif\",\n",
    "    max_count: int = 100,\n",
    "    trim_names: bool = True,\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any], List[str], Union[Dict[str, str], None]]:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Loads images and their corresponding masks from their respective directories.\n",
    "\n",
    "#### Parameters\n",
    "- `images_dir` (str): \n",
    "\n",
    "    Path to the directory containing the images.\n",
    "\n",
    "- `masks_dir` (str): \n",
    "\n",
    "    Path to the directory containing the masks.\n",
    "\n",
    "- `file_ext` (str, optional): \n",
    "\n",
    "    The file extension of the images and masks. Default is \"tif\".\n",
    "\n",
    "- `max_count` (int, optional): \n",
    "\n",
    "    The maximum number of image-mask pairs to load. Default is 100.\n",
    "\n",
    "- `trim_names` (bool, optional): \n",
    "\n",
    "    Whether to trim the image names. Default is True.\n",
    "\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- Tuple[Dict[str, Any], Dict[str, Any], List[str]]: \n",
    "\n",
    "    A tuple containing:\n",
    "\n",
    "    - `images` (Dict[str, Any]): \n",
    "    \n",
    "        Dictionary containing the images. Keys are image names.\n",
    "\n",
    "    - `masks` (Dict[str, Any]): \n",
    "    \n",
    "        Dictionary containing the masks. Keys are image names.\n",
    "\n",
    "    - `missing_masks` (List[str]): \n",
    "    \n",
    "        List containing the names of images with no associated masks.\n",
    "    \n",
    "    - `names_map` (Union[Dict[str, str], None]): \n",
    "    \n",
    "        If `trim_names` was `True` then it returns a dictionary with the new names as keys, and the old names as values. This can be used in the `save_predicted_masks` function from the [`unet.ipynb`](unet.ipynb) to get other associated files with the original name, such as `.twf` files which contain geospatial information.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If no images of the specified file type are found in the directory.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Example usage\n",
    "images_dir = \"path/to/images\"\n",
    "masks_dir = \"path/to/masks\"\n",
    "file_ext = \"tif\"\n",
    "max_count = 50\n",
    "trim_names = True\n",
    "\n",
    "# Load images and masks\n",
    "images, masks, missing_masks, names_map = load_images_and_masks(\n",
    "    images_dir, masks_dir, file_ext, max_count, trim_names\n",
    ")\n",
    "\n",
    "# Display the loaded images and masks\n",
    "print(f\"Loaded {len(images)} images and {len(masks)} masks.\")\n",
    "if missing_masks:\n",
    "    print(f\"Missing masks for images: {', '.join(missing_masks)}\")\n",
    "```\n",
    "#### Notes\n",
    "- The function normalizes the file extension to lowercase and strips any surrounding whitespace.\n",
    "- It retrieves the list of image files in the directory with the specified file extension.\n",
    "- The function limits the number of images to max_count if specified.\n",
    "- It initializes dictionaries to store images and masks, and a list for missing masks.\n",
    "- For each image, the function checks if the corresponding mask exists and loads both if available.\n",
    "- If a mask is missing, the image name is added to the missing_masks list, and the image is not loaded.\n",
    "- The function optionally trims the image names based on the trim_names flag.\n",
    "- The trimmed names are updated in the dictionaries for images and masks.\n",
    "A message is printed if any masks are missing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load in the images and associated masks\n",
    "def load_images_and_masks(\n",
    "    images_dir: str,\n",
    "    masks_dir: str,\n",
    "    file_ext: str = \"tif\",\n",
    "    max_count: int = 100,\n",
    "    trim_names: bool = True,\n",
    ") -> Tuple[Dict[str, Any], Dict[str, Any], List[str]]:\n",
    "    \"\"\"\n",
    "    Loads images and their corresponding masks from their respective directories.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Path to the directory containing the images.\n",
    "        masks_dir (str): Path to the directory containing the masks.\n",
    "        file_ext (str, optional): The file extension of the images and masks. Default is \"tif\".\n",
    "        max_count (int, optional): The maximum number of image-mask pairs to load. Default is 100 images.\n",
    "        trim_names (bool, optional): Whether to trim the image names. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, Any], Dict[str, Any], List[str]]: A tuple containing:\n",
    "            - images (Dict[str, Any]): Dictionary containing the images. Keys are image names.\n",
    "            - masks (Dict[str, Any]): Dictionary containing the masks. Keys are image names.\n",
    "            - missing_masks (List[str]): List containing the names of images with no associated masks.\n",
    "            - `names_map` (Dict[str, str]): If `trim_names` was `True` then it returns a dictionary with the new names as keys, and the old names as values. Otherwise it returns an empty dictionary.\n",
    "    \"\"\"\n",
    "    # Normalize file extension to lowercase and strip any surrounding whitespace\n",
    "    file_ext = file_ext.strip().lower()\n",
    "\n",
    "    # Get the list of image files in the directory with the specified file extension\n",
    "    images_dir_list = list(Path(images_dir).glob(\"*.\" + file_ext))\n",
    "    if not images_dir_list:\n",
    "        raise ValueError(\n",
    "            f\"No images of file type '{file_ext}' found in directory '{images_dir}'.\"\n",
    "        )\n",
    "\n",
    "    # Limit the number of images to max_count if specified. If max_count is greater than the number of available images, it will just get all images. \n",
    "    if max_count and max_count >= 1:\n",
    "        images_dir_list = images_dir_list[:max_count]\n",
    "\n",
    "    # Convert masks directory to Path object\n",
    "    masks_dir = Path(masks_dir)\n",
    "\n",
    "    # Initialize dictionaries to store images and masks, a list for missing masks, and a none \n",
    "    images = {}\n",
    "    masks = {}\n",
    "    missing_masks = []\n",
    "    names_map = {}\n",
    "\n",
    "    # Iterate over the list of image files\n",
    "    for image_path in images_dir_list:\n",
    "        file_name = image_path.stem # Get the file name without extension and without preceding directories.\n",
    "        mask_path = masks_dir / f\"{file_name}.{file_ext}\" # Construct the mask file path\n",
    "\n",
    "        # If the mask exists, load the image and mask, and store them in the dictionaries\n",
    "        if mask_path.exists():\n",
    "            image = Image.open(str(image_path))\n",
    "            mask = Image.open(str(mask_path))\n",
    "            images[file_name] = np.array(image)\n",
    "            masks[file_name] = np.array(mask)\n",
    "        else:\n",
    "            # If the mask does not exist, add the file name to the missing masks list\n",
    "            missing_masks.append(str(file_name))\n",
    "\n",
    "    # Print the missing masks if any\n",
    "    if missing_masks:\n",
    "        print(f\"The following masks are missing: {', '.join(missing_masks)}\\n\")\n",
    "        print(\"The images associated with the missing masks will not be included.\\n\")\n",
    "\n",
    "    # Optionally trim the names of the images and masks\n",
    "    if trim_names:\n",
    "        updated_names = []\n",
    "        buffer_digits = 1 # Extra digits to account for in the trimmed names\n",
    "        old_image_names, images = zip(*images.items())\n",
    "        _, masks = zip(*masks.items())\n",
    "\n",
    "        # Extract numeric part from the image names\n",
    "        for image_name in old_image_names:\n",
    "            str_match = re.search(r\"\\d+$\", image_name)\n",
    "            (\n",
    "                updated_names.append(str_match.group())\n",
    "                if str_match\n",
    "                else updated_names.append(image_name)\n",
    "            )\n",
    "        \n",
    "        # Determine the maximum number in the numeric part for padding purposes\n",
    "        numeric_file_names = [\n",
    "            int(file_name) for file_name in updated_names if file_name.isdigit()\n",
    "        ]\n",
    "        max_num = max(numeric_file_names)\n",
    "        char_count = len(str(max_num)) + buffer_digits\n",
    "\n",
    "        # Trim the image names to the appropriate length\n",
    "        image_names = [file_name[-char_count:] for file_name in updated_names]\n",
    "        \n",
    "        # Update the dictionaries with the trimmed names\n",
    "        images = dict(zip(image_names, images))\n",
    "        masks = dict(zip(image_names, masks))\n",
    "        names_map = dict(zip(image_names, old_image_names))\n",
    "    return (images, masks, missing_masks, names_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap Mask Classes\n",
    "The `remap_mask_classes` is a public function that remaps the mask classes to a subset of the original classes. \n",
    "\n",
    "#### remap_mask_classes\n",
    "```\n",
    "def remap_mask_classes(\n",
    "    masks: Dict[str, Any], class_mapping: Dict[int, int]\n",
    ") -> Dict[str, Any]:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Remaps the masks to the new classes based on the provided class mapping.\n",
    "\n",
    "#### Parameters\n",
    "- `masks` (Dict[str, Any]): \n",
    "\n",
    "    Dictionary containing the masks. Keys are mask names.\n",
    "\n",
    "- `class_mapping` (Dict[int, int]): \n",
    "\n",
    "    Dictionary mapping old class indices to new class indices. The keys are the old indices, and the values are the new indices.\n",
    "\n",
    "\n",
    "#### Returns\n",
    "\n",
    "- Dict[str, Any]: The remapped masks.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# Example masks and class mapping\n",
    "masks = {\n",
    "    \"mask1\": np.array([[0, 1, 2], [2, 1, 0]]),\n",
    "    \"mask2\": np.array([[1, 2, 3], [3, 2, 1]])\n",
    "}\n",
    "class_mapping = {0: 0, 1: 1, 2: 2, 3: 1}\n",
    "\n",
    "# Remap the mask classes\n",
    "remapped_masks, num_classes = remap_mask_classes(masks, class_mapping)\n",
    "\n",
    "# Display the remapped masks and number of new classes\n",
    "print(f\"Remapped Masks: {remapped_masks}\")\n",
    "print(f\"Number of Unique New Classes: {num_classes}\")\n",
    "```\n",
    "#### Notes\n",
    "- The function retrieves the masks as a list to check the number of classes present.\n",
    "- It identifies any classes that are out of range of the provided class mapping.\n",
    "- If there are classes out of range, the user is prompted to map these classes to a new class index or terminate the program.\n",
    "- The function creates an array version of the class mapping to apply to the masks.\n",
    "- It applies the mapping to each mask and calculates the new number of classes.\n",
    "- The function returns the remapped masks and the new number of classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remap the masks to a subset of the original classes\n",
    "def remap_mask_classes(\n",
    "    masks: Dict[str, Any], class_mapping: Dict[int, int]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remaps the masks to the new classes based on the provided class mapping.\n",
    "\n",
    "    Args:\n",
    "        masks (Dict[str, Any]): Dictionary containing the masks. Keys are mask names.\n",
    "        class_mapping (Dict[int, int]): Dictionary mapping old class indices to new class indices. The keys are the old indices, and the values are the new indices.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: The remapped masks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the masks as a list so that we can check how many classes there are\n",
    "    mask_names, masks_list = zip(*masks.items())\n",
    "    masks_list = np.stack(masks_list, axis=0)\n",
    "\n",
    "    # Get the unique class indices present in the masks\n",
    "    unique_classes = np.unique(masks_list)\n",
    "\n",
    "    # Get the maximum class index for the old classes in the mapping\n",
    "    max_class = max(class_mapping.keys())\n",
    "\n",
    "    # Identify any classes that are out of range of the provided class mapping\n",
    "    classes_out_of_range = unique_classes[unique_classes > max_class]\n",
    "\n",
    "    # Handle classes that are out of range of the mapping\n",
    "    if len(classes_out_of_range) > 0:\n",
    "        choose_class = (\n",
    "            input(\n",
    "                f\"There are classes found in the masks, that are not accounted for in the mapping: [{', '.join(map(str, classes_out_of_range))}].\\n\"\n",
    "                \"Would you like to map all out of range classes to a one of the new classes?\\n\"\n",
    "                \"(Note: If you select yes you will then be prompted for a value. If you select no the program will terminate.):\\n\"\n",
    "                \"(Y/N): \"\n",
    "            )\n",
    "            .strip()\n",
    "            .lower()\n",
    "        )\n",
    "        if choose_class == \"yes\" or choose_class == \"y\":\n",
    "            # Prompt the user to enter a new class index to map the out-of-range classes to\n",
    "            default_class = int(\n",
    "                input(\n",
    "                    f\"Please enter the new class index to map old indices [{', '.join(map(str, classes_out_of_range))}] to.\\n\"\n",
    "                    f\"You're options are [{', '.join(map(str, np.unique(list(class_mapping.values()))))}].\\n\"\n",
    "                    f\"New index: \"\n",
    "                )\n",
    "            )\n",
    "            # Update the class mapping dictionary to include the out-of-range classes\n",
    "            for class_idx in classes_out_of_range:\n",
    "                class_mapping[class_idx] = default_class\n",
    "        else:\n",
    "            # Exit the program if the user chooses not to map the out-of-range classes\n",
    "            sys.exit()\n",
    "\n",
    "    # Create an array version of the class mapping to apply to the masks\n",
    "    max_idx = max(class_mapping.keys())\n",
    "    mapping_array = np.zeros(max_idx + 1, dtype=np.uint16)\n",
    "    for old_idx, new_idx in class_mapping.items():\n",
    "        mapping_array[old_idx] = new_idx\n",
    "\n",
    "    # Apply the mapping to each mask\n",
    "    for mask_name, mask in masks.items():\n",
    "        masks[mask_name] = mapping_array[mask]\n",
    "\n",
    "    # Calculate the number of unique new classes\n",
    "    num_classes = len(set(class_mapping.values()))\n",
    "    return masks, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "\n",
    "The `view_data` function is a public function that is called in `main.ipynb` to view images and/or masks. It calls the internal function [`_display_samples`](#display-samples) to actually generate the necessary plots. \n",
    "\n",
    "#### view_data\n",
    "```\n",
    "def view_data(\n",
    "    images: Optional[Dict[str, Any]] = None,\n",
    "    masks: Optional[Dict[str, Any]] = None,\n",
    "    max_plots: int = 10,\n",
    "    max_cols: int = 5,\n",
    "    randomize: bool = False,\n",
    "    colors: bool = True,\n",
    ") -> None:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "View images or masks. A random subset of images can be viewed in color or grey.\n",
    "\n",
    "#### Parameters\n",
    "- `images` (Optional[Dict[str, Any]]): Dictionary of images. Keys are image names.\n",
    "- `masks` (Optional[Dict[str, Any]]): Dictionary of masks. Keys are mask names.\n",
    "- `max_plots` (int, optional): Maximum number of images or masks to show. Default is 10.\n",
    "- `max_cols` (int, optional): Maximum number of columns in the display grid. Default is 5.\n",
    "- `randomize` (bool, optional): Option to select a random subset from the images/masks. Default is False.\n",
    "- `colors` (bool, optional): Option to display the images or masks in color. Default is True.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If neither images nor masks are provided.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# Example images and masks\n",
    "images = {\n",
    "    \"image1\": np.random.rand(10, 10, 3),\n",
    "    \"image2\": np.random.rand(10, 10, 3),\n",
    "    \"image3\": np.random.rand(10, 10, 3)\n",
    "}\n",
    "masks = {\n",
    "    \"mask1\": np.random.randint(0, 2, (10, 10)),\n",
    "    \"mask2\": np.random.randint(0, 2, (10, 10)),\n",
    "    \"mask3\": np.random.randint(0, 2, (10, 10))\n",
    "}\n",
    "\n",
    "# View the images and masks\n",
    "view_data(images=images, masks=masks, max_plots=3, max_cols=2, randomize=True, colors=True)\n",
    "```\n",
    "#### Notes\n",
    "- The function verifies that at least images or masks are provided.\n",
    "- It ensures that the maximum number of columns is between 1 and 10.\n",
    "- It ensures that the maximum number of plots is at least 1.\n",
    "- If images are provided, the function prepares to display them, adjusting max_plots if it exceeds the number of available samples.\n",
    "- The function selects a subset of sample names to display, either in order or randomly.\n",
    "- It calls the `_display_samples` function to display the selected images or masks.\n",
    "- If masks are provided, the function prepares to display them similarly to images.\n",
    "- The function handles cases where images and masks are both provided or only one of them is provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to view the images, masks, or both \n",
    "def view_data(\n",
    "    images: Optional[Dict[str, Any]] = None,\n",
    "    masks: Optional[Dict[str, Any]] = None,\n",
    "    max_plots: int = 10,\n",
    "    max_cols: int = 5,\n",
    "    randomize: bool = False,\n",
    "    colors: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    View images or masks. Random subset of images can be viewed in color or grey.\n",
    "\n",
    "    Args:\n",
    "        images (Optional[Dict[str, Any]]): Dictionary of images. Keys are image names.\n",
    "        masks (Optional[Dict[str, Any]]): Dictionary of masks. Keys are mask names.\n",
    "        max_plots (int, optional): Maximum number of images or masks to show. Default is 10.\n",
    "        max_cols (int, optional): Maximum number of columns in the display grid. Default is 5.\n",
    "        randomize (bool, optional): Option to select a random subset from the images/masks. Default is False.\n",
    "        colors (bool, optional): Option to display the images or masks in color. Default is True.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verify that at least images or masks are provided.\n",
    "    if images is None and masks is None:\n",
    "        raise ValueError(\"You must provide either 'images' and/or 'masks' to view.\")\n",
    "\n",
    "    # Ensure that the maximum number of columns is a reasonable value\n",
    "    if max_cols < 1 or max_cols > 10:\n",
    "        print(\"max_cols should be between 1 and 10. Defaulting to 5.\")\n",
    "        max_cols = 5\n",
    "\n",
    "    # Ensure that the maximum number of plots is a reasonable value\n",
    "    if max_plots < 1:\n",
    "        print(\"max_plots should be 1 or greater. Defaulting to 1.\")\n",
    "        max_plots = 1\n",
    "\n",
    "    # If images are provided, prepare to display them\n",
    "    if images is not None:\n",
    "        sample_type = 0 # Indicate that we are displaying images\n",
    "        sample_names = list(images.keys())\n",
    "        sample_count = len(sample_names)\n",
    "\n",
    "        # Adjust max_plots if it exceeds the number of available samples\n",
    "        if max_plots > sample_count:\n",
    "            print(\n",
    "                f\"max_plots ({max_plots}) exceeds the number of samples ({sample_count}). All samples will be displayed.\"\n",
    "            )\n",
    "            max_plots = sample_count\n",
    "\n",
    "        # Select a subset of sample names to display, either an ordered subset or a random subset\n",
    "        if not randomize:\n",
    "            sample_names = sample_names[:max_plots]\n",
    "        else:\n",
    "            sample_names = random.sample(sample_names, max_plots)\n",
    "\n",
    "        # Display the selected images\n",
    "        _display_samples(\n",
    "            images, sample_names, sample_type, max_cols, max_plots, colors, scale=1\n",
    "        )\n",
    "\n",
    "    # If masks are provided, prepare to display them\n",
    "    if masks is not None:\n",
    "        sample_type = 1 # Indicate that we are displaying masks\n",
    "\n",
    "        # If no images are provided, determine the sample names, max_plots, and randomization from the function inputs. If images are provided then the information in this `if` statement, is already captured. \n",
    "        if images is None:\n",
    "            sample_names = list(masks.keys())\n",
    "            sample_count = len(sample_names)\n",
    "\n",
    "            # Adjust max_plots if it exceeds the number of available samples\n",
    "            if max_plots > sample_count:\n",
    "                print(\n",
    "                    f\"max_plots ({max_plots}) exceeds the number of samples ({sample_count}). Will display all samples.\"\n",
    "                )\n",
    "                max_plots = sample_count\n",
    "\n",
    "            # Select a subset of sample names to display, either an ordered subset or a random subset\n",
    "            if not randomize:\n",
    "                sample_names = sample_names[:max_plots]\n",
    "            else:\n",
    "                sample_names = random.sample(sample_names, max_plots)\n",
    "\n",
    "        # Display the selected images\n",
    "        _display_samples(\n",
    "            masks, sample_names, sample_type, max_cols, max_plots, colors, scale=1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Images and Masks\n",
    "The `preprocess_images_and_masks` function is a public function that preprocesses the images and masks to prepare them for the U-Net. This includes verify the number of classes, and the format of the image and mask data. It is capable of handling cases where the number of classes in the masks does not match the input number of classes, and it will request information from the user in those cases. It then displays some details about the preprocessed images and masks, for verification. It specifically returns to the preprocessed images, the preprocessed masks, the threshold value used for binary masks, the image names, and the number of classes in the preprocessed masks. \n",
    "\n",
    "#### preprocess_images_and_masks\n",
    "```\n",
    "def preprocess_images_and_masks(\n",
    "    images: Dict[str, Any],\n",
    "    masks: Dict[str, Any],\n",
    "    num_classes: int = 3,\n",
    "    target_size: Tuple[int, int] = (256, 256),\n",
    "    threshold: float = 0.5,\n",
    ") -> Tuple[np.ndarray, np.ndarray, float, List[str], int]:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Preprocesses the images and masks into the correct format for use in the U-Net.\n",
    "\n",
    "#### Parameters\n",
    "- `images` (Dict[str, Any]): Dictionary of images. Keys are image names.\n",
    "- `masks` (Dict[str, Any]): Dictionary of masks. Keys are mask names.\n",
    "- `num_classes` (int, optional): Number of classes in the masks. Default is 3.\n",
    "- `target_size` (Tuple[int, int], optional): Target size of the images. Default is (256, 256).\n",
    "- `threshold` (float, optional): Threshold to use if the number of classes is 1 (binary). Default is 0.5.\n",
    "\n",
    "#### Returns\n",
    "- Tuple[np.ndarray, np.ndarray, float, List[str], int]: \n",
    "\n",
    "    A tuple containing:\n",
    "\n",
    "    - `images` (np.ndarray): \n",
    "    \n",
    "        Processed images as numpy arrays.\n",
    "\n",
    "    - `masks` (np.ndarray): \n",
    "    \n",
    "        Processed masks as numpy arrays.\n",
    "\n",
    "    - `threshold` (float): \n",
    "    \n",
    "        Threshold to use if the number of classes is 1 (binary).\n",
    "\n",
    "    - `image_names` (List[str]): \n",
    "    \n",
    "        Image names to be used in plotting labels.\n",
    "\n",
    "    - `num_classes` (int): \n",
    "    \n",
    "        Number of classes in the masks.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If the number of channels in the masks does not match the expected number of classes.\n",
    "- `ValueError`: If the masks have an unexpected number of dimensions.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# Example images and masks\n",
    "images = {\n",
    "    \"image1\": np.random.rand(256, 256, 3),\n",
    "    \"image2\": np.random.rand(256, 256, 3),\n",
    "    \"image3\": np.random.rand(256, 256, 3)\n",
    "}\n",
    "masks = {\n",
    "    \"mask1\": np.random.randint(0, 3, (256, 256)),\n",
    "    \"mask2\": np.random.randint(0, 3, (256, 256)),\n",
    "    \"mask3\": np.random.randint(0, 3, (256, 256))\n",
    "}\n",
    "\n",
    "# Preprocess the images and masks\n",
    "processed_images, processed_masks, threshold, image_names, num_classes = preprocess_images_and_masks(\n",
    "    images, masks, num_classes=3, target_size=(256, 256), threshold=0.5\n",
    ")\n",
    "```\n",
    "#### Notes\n",
    "- The function converts the images to float32 numpy arrays, scales them to the range [0, 1], and resizes them to the target size.\n",
    "- It converts the masks to a stack for easier manipulation and checks the number of unique classes.\n",
    "- The function handles cases where the number of unique classes differs from the input `num_classes`.\n",
    "- It checks if the masks are already one-hot encoded and handles cases where they are not.\n",
    "- The function resizes the masks to the target size and converts them to float32 numpy arrays.\n",
    "- It prints information about the preprocessed data, including the number of images, shape of the dataset, and number of classes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the images and masks into the right structures for the Tensorflow U-Net.\n",
    "def preprocess_images_and_masks(\n",
    "    images: Dict[str, Any],\n",
    "    masks: Dict[str, Any],\n",
    "    num_classes: int = 3,\n",
    "    target_size: Tuple[int, int] = (256, 256),\n",
    "    threshold: float = 0.5,\n",
    ") -> Tuple[np.ndarray, np.ndarray, float, List[str], int]:\n",
    "    \"\"\"\n",
    "    Preprocesses the images and masks into the correct format for use in the U-Net.\n",
    "\n",
    "    Args:\n",
    "        images (Dict[str, Any]): Dictionary of images. Keys are image names.\n",
    "        masks (Dict[str, Any]): Dictionary of masks. Keys are mask names.\n",
    "        num_classes (int,optional): Number of classes in the masks. Default is assumed to be 3, but will be checked against masks input.\n",
    "        target_size (Tuple[int, int],optional): Target size of the images. Default is assumed to be (256,256)\n",
    "        threshold (float, optional): Threshold to  use if the number of classes is 1 (binary).(binary). Default is 0.5.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: A tuple containing:\n",
    "            - images (np.ndarray): processed images as numpy arrays.\n",
    "            - masks (np.ndarray): processed masks as numpy arrays.\n",
    "            - threshold (float): Threshold to  use if the number of classes is 1 (binary).\n",
    "            - image_names (List[str]): Image names to be used in plotting labels\n",
    "            - num_classes (int): Number of classes in the masks.\n",
    "    \"\"\"\n",
    "    # Get the images and their names\n",
    "    image_names, images = zip(*images.items())\n",
    "\n",
    "    # Convert the images to the appropriate format, in this case a float32 numpy array\n",
    "    images = tf.stack(images)\n",
    "    images = tf.cast(images, dtype=tf.float32) / 255 # Scale the images down from RGB 255 range to 0 to 1 range\n",
    "    images = tf.image.resize(images, target_size, method=tf.image.ResizeMethod.BILINEAR) # Resize the images to the desired shape\n",
    "    images = images.numpy()\n",
    "\n",
    "    # Get the masks and their names\n",
    "    mask_names, masks = zip(*masks.items())\n",
    "\n",
    "    # Conver the masks to a stack for easier manipulation\n",
    "    masks = tf.stack(masks)\n",
    "\n",
    "    # Check the number of mask classes\n",
    "    unique_classes = np.unique(masks)\n",
    "\n",
    "    # Get the full list of the possible classes. Note this is necessary for proper one-hot encoding\n",
    "    unique_class_range = list(range(max(unique_classes) + 1))\n",
    "    num_unique_classes = len(unique_class_range)\n",
    "\n",
    "    # Handle the case where the number of unique classes differs from the input num_classes\n",
    "    if num_unique_classes < 20:\n",
    "        # If the number of detected classes is less than the number of input classes you can optional choose to use the detected number of classes input, or choose to continue with the input number of classes. \n",
    "        if num_unique_classes < num_classes:\n",
    "            choose_classes = (\n",
    "                input(\n",
    "                    f\"There have been {num_unique_classes} mask classes detected, which differs from the input of {num_classes} mask classes.\\n\"\n",
    "                    f\"Would you like to use the detected number of classes {num_unique_classes}?\\n\"\n",
    "                    \"(Note: To err on the side of caution it is recommended to choose the larger number.):\\n\"\n",
    "                    \"(Y/N): \"\n",
    "                )\n",
    "                .strip()\n",
    "                .lower()\n",
    "            )\n",
    "            if choose_classes == \"yes\" or choose_classes == \"y\":\n",
    "                num_classes = num_unique_classes\n",
    "\n",
    "        # If the detected number of classes detected is larger than the number of input classes, then you must either opt to use detected number of classes or terminate the program.\n",
    "        elif num_unique_classes > num_classes:\n",
    "            if not (num_unique_classes == 2 and num_classes == 1):\n",
    "                warnings.warn(\n",
    "                    f\"Detected {num_unique_classes} classes, which is larger than the input {num_classes} classes.\\n\"\n",
    "                    f\"You must have at least the the number of possible classes, in this case {num_unique_classes}, with the following classes: \"\n",
    "                    f\"[{', '.join(map(str, unique_class_range))}]\",\n",
    "                    UserWarning,\n",
    "                )\n",
    "\n",
    "                choose_classes = (\n",
    "                    input(\n",
    "                        f\"Would you like to use the detected number of classes {num_unique_classes}?\\n\"\n",
    "                        \"(Note: If you select no, the program will terminate.):\\n\"\n",
    "                        \"(Y/N): \"\n",
    "                    )\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                )\n",
    "                if choose_classes == \"yes\" or choose_classes == \"y\":\n",
    "                    num_classes = num_unique_classes\n",
    "                else:\n",
    "                    sys.exit()\n",
    "    # If the detected number of classes is greater than 20, and the input number of classes was not already set to 1, it indicates the image is likely greyscale (values ranging between 0 and 1). In this case we will automatically treat it as such, with a single class.\n",
    "    elif num_classes != 1:\n",
    "        print(\n",
    "            f\"The image appears to be a grey-scale image because it appears to have more than 20 'classes': {num_unique_classes}.\\n\"\n",
    "            f\"We will treat this as grey-scale image, to be binary sorted into foreground and background using the threshold: {threshold}.\"\n",
    "        )\n",
    "        num_classes = 1\n",
    "\n",
    "    \n",
    "    already_one_hot = False\n",
    "    # Handle cases where the masks may or may not already be one hot encoded (4th dimension of a value other than 1)\n",
    "    if len(masks.shape) == 4:\n",
    "\n",
    "        # If the mask shape looks like it is already one hot encoded (the 4th dimension matches the number of classes), ask the user to verify this as correct or to let us know that this is wrong. If it is not one hot encoded but has multiple channels, then it will select only the first channel, based on the assumption that all the channels contain the same information. \n",
    "        if masks.shape[-1] == num_classes:\n",
    "            verify = (\n",
    "                input(\n",
    "                    f\"You're masks already have {num_classes} channels.\\n\"\n",
    "                    \"Do these channels represent the number of classes?\\n\"\n",
    "                    \"(Note: selecting YES assumes the data is already one-hot encoded)\\n\"\n",
    "                    \"(Y/N):\"\n",
    "                )\n",
    "                .strip()\n",
    "                .lower()\n",
    "            )\n",
    "\n",
    "            # If the user says yes, use the channels and assume already one-hot encoded\n",
    "            if verify == \"yes\" or verify == \"y\":\n",
    "                print(\n",
    "                    f\"Will assume that the number of channels == the number of classes == {num_classes}.\\n\"\n",
    "                )\n",
    "                already_one_hot = True\n",
    "\n",
    "            # If the user doesn't say yes, verify the user wants to use the first channel.\n",
    "            else:\n",
    "                first_channel = (\n",
    "                    input(\n",
    "                        \"Do you want to only use the first channel?\\n\"\n",
    "                        \"(Note: If you select NO, the program will terminate.)\\n\"\n",
    "                        \"(Y/N):\"\n",
    "                    )\n",
    "                    .strip()\n",
    "                    .lower()\n",
    "                )\n",
    "\n",
    "                # If the user says yes, use the first channel, assuming they are all the same.\n",
    "                if first_channel == \"yes\" or first_channel == \"y\":\n",
    "                    warnings.warn(\n",
    "                        f\"Expected {num_classes} classes, but found {masks.shape[-1]}.\\n\"\n",
    "                        \"Only using the first channel.\\n\",\n",
    "                        UserWarning,\n",
    "                    )\n",
    "                    masks = masks[:, :, :, 0]\n",
    "                    masks = tf.expand_dims(masks, axis=-1)\n",
    "\n",
    "                # If the user doesn't say yes, terminate the program.\n",
    "                else:\n",
    "                    sys.exist()\n",
    "\n",
    "        # If the number of channels (the 4th dimension of the mask) does not match the number of classes and it is not a single channel (which indicates either greyscale or that the classes are all captured in the single channel by having discrete values in the channel such as 0,1,2,3 etc.), raise an error.\n",
    "        elif masks.shape[-1] != 1:\n",
    "            raise ValueError(\n",
    "                f\"Unexpected number of channels ({masks.shape[-1]}).\\n\"\n",
    "                f\"Expected either 1 (where the single channel contains all classes) or {num_classes} (where the number of channels == the number of classes).\\n\"\n",
    "            )\n",
    "    # If the masks does not have a 4th dimension, then just add the 4th dimension to achieve the necessary shape for one-hot encoding.\n",
    "    elif len(masks.shape) == 3:\n",
    "        masks = tf.expand_dims(masks, axis=-1)\n",
    "    # If the masks is not shape 3 or 4, then raise an error.\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unexpected number of dimensions for masks: {len(masks.shape)}.\\n\"\n",
    "        )\n",
    "\n",
    "    # Convert the masks to an int type for resizing, and then resize to desired shape\n",
    "    masks = tf.cast(masks, dtype=tf.uint8)\n",
    "    masks = tf.image.resize(\n",
    "        masks, target_size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "    )\n",
    "    masks = tf.cast(masks, dtype=tf.uint8)\n",
    "\n",
    "    # Check if the masks are already one-hot encoded\n",
    "    if not already_one_hot:\n",
    "        masks = masks[:, :, :, 0]\n",
    "        # If there is only one class, then treat it as binary case (foreground and background)\n",
    "        if num_classes == 1:\n",
    "            threshold_255 = int(threshold * 255)\n",
    "            masks = tf.cast(masks > threshold_255, tf.int32)\n",
    "\n",
    "        # If the number of classes is 2, then still treat it as binary case, but inform the user of the change (foreground and background)\n",
    "        elif num_classes == 2:\n",
    "            print(\n",
    "                \"Data has only two classes.\\n\"\n",
    "                \"Masks will be converted to binary masks for faster evaluation.\"\n",
    "            )\n",
    "            foreground = max(unique_class_range) # Use the larger value as the foreground (1) class.\n",
    "            masks = tf.where(masks == foreground, 1, 0)\n",
    "            num_classes = 1\n",
    "        else:\n",
    "            masks = tf.cast(masks, tf.int32)\n",
    "            masks = tf.one_hot(masks, depth=num_classes)\n",
    "\n",
    "    # Convert the masks the appropriate format, in this case a float32 numpy array\n",
    "    masks = tf.cast(masks, tf.float32)\n",
    "    masks = masks.numpy()\n",
    "\n",
    "    # Print information about the preprocessed data\n",
    "    print(\"Preprocessed data information:\")\n",
    "    print(f\"Number of images: {len(images)}.\")\n",
    "    print(f\"Shape of images dataset: {images.shape}.\")\n",
    "    print(f\"Images type: {images.dtype}.\")\n",
    "    print(f\"Number of masks: {len(masks)}.\")\n",
    "    print(f\"Shape of masks dataset: {masks.shape}.\")\n",
    "    print(f\"Masks type: {masks.dtype}.\")\n",
    "    print(f\"Number of classes: {num_classes}.\")\n",
    "\n",
    "    return (images, masks, threshold, image_names, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Datasets\n",
    "\n",
    "The `save_datasets` function is a public function called in `main.ipynb`, to save  split datasets into individual `.npy` files, for later use. \n",
    "\n",
    "#### save_datasets\n",
    "```\n",
    "def save_datasets(\n",
    "    training: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    test: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    validation: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    save_dir: str = \"Datasets\",\n",
    ") -> None:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Saves the training, test, and validation datasets to the specified directory.\n",
    "\n",
    "#### Parameters\n",
    "- `save_dir` (str, optional): \n",
    "\n",
    "    Path to the directory where the datasets are saved. Default is \"Datasets\"\n",
    "\n",
    "- `training` Optional[Tuple[np.ndarray, np.ndarray]]: \n",
    "\n",
    "    Training dataset set to be saved, images and then masks. Default is None.\n",
    "\n",
    "- `test` Optional[Tuple[np.ndarray, np.ndarray]]: \n",
    "\n",
    "    Test dataset set to be saved, images and then masks. Default is None.\n",
    "\n",
    "- `validation` Optional[Tuple[np.ndarray, np.ndarray]]: \n",
    "\n",
    "    Validation dataset set to be saved, images and then masks. Default is None.\n",
    "\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If none of the datasets (training, test, validation) are provided to save.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "training_data = (np.random.rand(10, 10), np.random.rand(10, 10))\n",
    "test_data = (np.random.rand(10, 10), np.random.rand(10, 10))\n",
    "validation_data = (np.random.rand(10, 10), np.random.rand(10, 10))\n",
    "\n",
    "# Save the datasets to the specified directory\n",
    "save_datasets(\n",
    "    training=training_data,\n",
    "    test=test_data,\n",
    "    validation=validation_data,\n",
    "    save_dir=\"my_datasets\"\n",
    ")\n",
    "```\n",
    "#### Notes\n",
    "- Ensure that at least one of the datasets (training, test, validation) is provided to save.\n",
    "- The function converts the `save_dir` to a `Path` object for easier path manipulations.\n",
    "- A message is printed to indicate the save directory once the data is saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets(\n",
    "    training: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    test: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    validation: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n",
    "    save_dir: str = \"Datasets\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves the training, test, and validation datasets to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        training (Optional[Tuple[np.ndarray, np.ndarray]], optional): Tuple containing training images and masks. Default is None.\n",
    "        test (Optional[Tuple[np.ndarray, np.ndarray]], optional): Tuple containing test images and masks. Default is None.\n",
    "        validation (Optional[Tuple[np.ndarray, np.ndarray]], optional): Tuple containing validation images and masks. Default is None.\n",
    "        save_dir (str, optional): Path to the directory where the datasets will be saved. Default is \"Datasets\".\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that at least one of the datasets (training, test, validation) is provided\n",
    "    if not (training and test and validation):\n",
    "        raise ValueError(\n",
    "            \"You must provide at least one of the three data types to save: training, test, or validation.\"\n",
    "        )\n",
    "\n",
    "    # Create the save directory if it doesn't exist\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the training dataset if provided\n",
    "    if training:\n",
    "        np.save(save_dir / \"images_training.npy\", training[0])\n",
    "        np.save(save_dir / \"masks_training.npy\", training[1])\n",
    "\n",
    "    # Save the test dataset if provided\n",
    "    if test:\n",
    "        np.save(save_dir / \"images_test.npy\", test[0])\n",
    "        np.save(save_dir / \"masks_test.npy\", test[1])\n",
    "\n",
    "    # Save the validation dataset if provided\n",
    "    if validation:\n",
    "        np.save(save_dir / \"images_validation.npy\", validation[0])\n",
    "        np.save(save_dir / \"masks_validation.npy\", validation[1])\n",
    "\n",
    "    print(f\"Data saved in {save_dir}.\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "The `load_datasets` function is a public function called in `main.ipynb`, to load a preexisting presplit dataset that was saved in the format used by [`save_datasets`](#save-datasets). \n",
    "\n",
    "#### load_datasets\n",
    "```\n",
    "def load_datasets(\n",
    "    load_dir: str,\n",
    "    training: bool = True,\n",
    "    test: bool = True,\n",
    "    validation: bool = True,\n",
    ") -> Tuple[\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "]:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Loads the training, test, and validation datasets from the specified directory.\n",
    "\n",
    "#### Parameters\n",
    "- `load_dir` (str): \n",
    "\n",
    "    Path to the directory where the datasets are stored.\n",
    "\n",
    "- `training` (bool, optional): \n",
    "\n",
    "    Whether to load the training dataset. Default is True.\n",
    "\n",
    "- `test` (bool, optional): \n",
    "\n",
    "    Whether to load the test dataset. Default is True.\n",
    "\n",
    "- `validation` (bool, optional): \n",
    "\n",
    "    Whether to load the validation dataset. Default is True.\n",
    "\n",
    "#### Returns\n",
    "- Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]\n",
    "\n",
    "    A tuple containing:\n",
    "\n",
    "    - `images_training` (Optional[np.ndarray]):\n",
    "\n",
    "        The training images.\n",
    "\n",
    "    - `masks_training` (Optional[np.ndarray]): \n",
    "    \n",
    "        The training masks.\n",
    "\n",
    "    - `images_test` (Optional[np.ndarray]): \n",
    "\n",
    "        The test images.\n",
    "\n",
    "    - `masks_test` (Optional[np.ndarray]): \n",
    "\n",
    "        The test masks.\n",
    "\n",
    "    - `images_validation` (Optional[np.ndarray]):\n",
    "\n",
    "        The validation images.\n",
    "\n",
    "    - `masks_validation` (Optional[np.ndarray]): \n",
    "\n",
    "        The validation masks.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If none of the datasets (training, test, validation) is selected to load.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets from the specified directory\n",
    "images_training, masks_training, images_test, masks_test, images_validation, masks_validation = load_datasets(\n",
    "    load_dir=\"path/to/datasets\",\n",
    "    training=True,\n",
    "    test=True,\n",
    "    validation=True\n",
    ")\n",
    "```\n",
    "#### Notes\n",
    "- Ensure that at least one of the datasets (training, test, validation) is selected to load.\n",
    "- The function converts the `load_dir` to a `Path` object for easier path manipulations.\n",
    "- If a dataset type is not selected, its corresponding return value will be `None`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(\n",
    "    load_dir: str,\n",
    "    training: bool = True,\n",
    "    test: bool = True,\n",
    "    validation: bool = True,\n",
    ") -> Tuple[\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "    Optional[np.ndarray],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Loads the training, test, and validation datasets from the specified directory.\n",
    "\n",
    "    Args:\n",
    "        load_dir (str): Path to the directory where the datasets are stored.\n",
    "        training (bool, optional): Whether to load the training dataset. Default is True.\n",
    "        test (bool, optional): Whether to load the test dataset. Default is True.\n",
    "        validation (bool, optional): Whether to load the validation dataset. Default is True.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "        A tuple containing:\n",
    "            - images_training (Optional[np.ndarray]): The training images.\n",
    "            - masks_training (Optional[np.ndarray]): The training masks.\n",
    "            - images_test (Optional[np.ndarray]): The test images.\n",
    "            - masks_test (Optional[np.ndarray]): The test masks.\n",
    "            - images_validation (Optional[np.ndarray]): The validation images.\n",
    "            - masks_validation (Optional[np.ndarray]): The validation masks.\n",
    "    \"\"\"\n",
    "    # Ensure that at least one of the datasets (training, test, validation) is selected to load\n",
    "    if not (training and test and validation):\n",
    "        raise ValueError(\n",
    "            \"You must select at least one of the three data types to load: training, test, or validation.\"\n",
    "        )\n",
    "    load_dir = Path(load_dir) # Convert the load directory to a Path object\n",
    "\n",
    "    # Initialize variables for datasets\n",
    "    images_training, masks_training = None, None\n",
    "    images_test, masks_test = None, None\n",
    "    images_validation, masks_validation = None, None\n",
    "\n",
    "    # Load the training dataset if selected\n",
    "    if training:\n",
    "        images_training = np.load(load_dir / \"images_training.npy\")\n",
    "        masks_training = np.load(load_dir / \"masks_training.npy\")\n",
    "\n",
    "    # Load the test dataset if selected\n",
    "    if test:\n",
    "        images_test = np.load(load_dir / \"images_test.npy\")\n",
    "        masks_test = np.load(load_dir / \"masks_test.npy\")\n",
    "\n",
    "    # Load the validation dataset if selected\n",
    "    if validation:\n",
    "        images_validation = np.load(load_dir / \"images_validation.npy\")\n",
    "        masks_validation = np.load(load_dir / \"masks_validation.npy\")\n",
    "\n",
    "    return (\n",
    "        images_training,\n",
    "        masks_training,\n",
    "        images_test,\n",
    "        masks_test,\n",
    "        images_validation,\n",
    "        masks_validation,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Associated Files\n",
    "\n",
    "The `save_associated_files` function is a public function called in `main.ipynb` to copy files from one directory and save them to another. This is relevant in the case of `.tif` files with associated `.tfw` that contain necessary geospatial information. When the predicted masks are created, their geospatial data does not change, so we would want to include those files with predicted masks. \n",
    "\n",
    "Note that **if a `names_map` is provided, for each file found based on a given value from the dictionary, the file will be renamed to the associated key from the dictionary**. For example if I had a key-value pair of `{new_name: original_name}`, then the file `original_name` found in the `original_dir` will be copied to `output_dir` and saved under the name `new_name`. **This means that if there are any existing files in the folder, with the same name and file type they will be overwritten.** \n",
    "\n",
    "#### save_associated_files\n",
    "\n",
    "```\n",
    "def save_associated_files(\n",
    "    original_dir: str,\n",
    "    output_dir: str,\n",
    "    file_ext: str = \"tfw\",\n",
    "    file_names: Optional[List[str]] = None,\n",
    "    names_map: Optional[Dict[str, str]] = None,\n",
    ") -> None:\n",
    "```\n",
    "#### Description\n",
    "\n",
    "Copies associated files from the original directory to the output directory.\n",
    "\n",
    "#### Parameters\n",
    "- `original_dir` (str): \n",
    "\n",
    "    Path to the directory containing the original files.\n",
    "\n",
    "- `output_dir` (str): \n",
    "\n",
    "    Path to the directory where the files will be saved.\n",
    "\n",
    "- `file_ext` (str, optional): \n",
    "\n",
    "    File extension of the associated files. Default is `tfw`.\n",
    "\n",
    "- `file_names` (Optional[List[str]], optional): \n",
    "\n",
    "    List of file names to copy. If `None`, all files with the specified extension will be copied. Default is `None`.\n",
    "\n",
    "- `names_map` (Optional[Dict[str, str]], optional): \n",
    "\n",
    "    Dictionary mapping file names to their corresponding names in the original directory. Default is None.\n",
    "\n",
    "#### Raises\n",
    "- `ValueError`: If no files of the specified file type are found in the directory.\n",
    "\n",
    "#### Example\n",
    "```\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Example usage\n",
    "original_dir = \"path/to/original\"\n",
    "output_dir = \"path/to/output\"\n",
    "file_ext = \"tfw\"\n",
    "file_names = [\"file1\", \"file2\", \"file3\"]\n",
    "names_map = {\"file1\": \"original_file1\", \"file2\": \"original_file2\", \"file3\": \"original_file3\"}\n",
    "\n",
    "# Save the associated files\n",
    "save_associated_files(original_dir, output_dir, file_ext, file_names, names_map)\n",
    "```\n",
    "#### Notes\n",
    "- The function creates the output_dir if it does not exist.\n",
    "- It normalizes the file extension to lowercase and strips any surrounding whitespace.\n",
    "- The function retrieves the list of files in the original directory with the specified file extension.\n",
    "- If `file_names` is provided, it copies the specified files. If `names_map` is provided, it uses the mapping to find the corresponding file names in the original directory, and when saving renames it to file name from the `names_map` key.\n",
    "- If `file_names` is not provided, it copies all files with the specified extension.\n",
    "- The function prints a message if any files are missing from the original directory or the names_map.\n",
    "- A message is printed to indicate the output directory once the files are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_associated_files(\n",
    "    original_dir: str,\n",
    "    output_dir: str,\n",
    "    file_ext: str = \"tfw\",\n",
    "    file_names: Optional[List[str]] = None,\n",
    "    names_map: Optional[Dict[str, str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Copies associated files from the original directory to the output directory.\n",
    "\n",
    "    Args:\n",
    "        original_dir (str): Path to the directory containing the original files.\n",
    "        output_dir (str): Path to the directory where the files will be saved.\n",
    "        file_ext (str, optional): File extension of the associated files. Default is \"tfw\".\n",
    "        file_names (Optional[List[str]], optional): List of file names to copy. If None, all files with the specified extension will be copied. Default is None.\n",
    "        names_map (Optional[Dict[str, str]], optional): Dictionary mapping file names to their corresponding names in the original directory. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convert original directory to Path object\n",
    "    original_dir = Path(original_dir)\n",
    "\n",
    "    # Normalize file extension to lowercase and strip any surrounding whitespace\n",
    "    file_ext = file_ext.strip().lower()\n",
    "\n",
    "    # Initialize empty missing files and keys\n",
    "    missing_files = []\n",
    "    missing_keys = []\n",
    "\n",
    "    # Get the list of files in the original directory with the specified file extension\n",
    "    original_files_list = list(Path(original_dir).glob(\"*.\" + file_ext))\n",
    "\n",
    "    # If no files with the given extension are found in the original directory, raise an error.\n",
    "    if not original_files_list:\n",
    "        raise ValueError(\n",
    "            f\"No files of file type '{file_ext}' found in directory '{original_dir}'.\"\n",
    "        )\n",
    "\n",
    "    # If specific file names are provided, then either match them to the names_map if provided, or directly search for them in the original directory.\n",
    "    if file_names:\n",
    "        if names_map:\n",
    "            # If a names_map is provided, map the file names accordingly\n",
    "            keys = [key for key in file_names if key in names_map]\n",
    "            missing_keys = list(set(file_names) - set(keys))  # Identify missing keys\n",
    "            for key in keys:\n",
    "                file_name = names_map[key]\n",
    "                src_file = original_dir / f\"{file_name}.{file_ext}\"\n",
    "                output_file = output_dir / f\"{key}.{file_ext}\"\n",
    "                if src_file.exists():\n",
    "                    shutil.copy2(\n",
    "                        src_file, output_file\n",
    "                    )  # Copy the file to the output directory, with the same name as the key \n",
    "                else:\n",
    "                    missing_files.append(str(file_name))  # Track missing files\n",
    "        else:\n",
    "            # If no names_map is provided, use the file names directly\n",
    "            for file_name in file_names:\n",
    "                src_file = original_dir / f\"{file_name}.{file_ext}\"\n",
    "                if src_file.exists():\n",
    "                    shutil.copy2(\n",
    "                        src_file, output_dir\n",
    "                    )  # Copy the file to the output directory\n",
    "                else:\n",
    "                    missing_files.append(str(file_name))  # Track missing files\n",
    "    else:\n",
    "        # If no specific file names are provided, copy all files with the specified extension\n",
    "        for src_file in original_files_list:\n",
    "            shutil.copy2(src_file, output_dir)\n",
    "\n",
    "    # Print missing files if any\n",
    "    if missing_files:\n",
    "        print(\n",
    "            f\"The following files are missing from {original_dir}: \\n{', '.join(missing_files)}\\n\"\n",
    "        )\n",
    "    # Print missing keys if any\n",
    "    if missing_keys:\n",
    "        print(\n",
    "            f\"The following files are missing from `names_map`: \\n{', '.join(missing_keys)}\\n\"\n",
    "        )\n",
    "\n",
    "    print(f\"Files saved to {output_dir}.\")\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
