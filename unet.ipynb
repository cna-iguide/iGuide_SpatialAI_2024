{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net and Associated Functions\n",
    "\n",
    "## Overview\n",
    "This notebook contains the  U-Net and it's associated functions. All functions contain doc strings which define the function inputs and outputs, and their data types. There are also comments throughout each function for additional clarity.\n",
    "\n",
    "## Structure\n",
    "- **[Import Necessary Packages](#import-necessary-packages)**: Importing the necessary packages used by functions in this notebook.\n",
    "- **[Internal Functions](#internal-functions)**: Internal or private functions that are only called by other functions and should never be called directly by a script. \n",
    "    - [`_get_colors`](#get-colors): \n",
    "    - [`_get_class_labels`](#get-class-labels): \n",
    "    - [`_get_color_masks`](#get-colored-masks): \n",
    "    - [`_compute_basic_metrics`](#compute-basic-metrics):\n",
    "    - [`_view_predictions`](#view-predictions):\n",
    "- **[Public Functions](#public-functions)**: Public functions to be imported and called by other scripts, outside of this notebook. \n",
    "    - [`iou_metric`](#intersection-over-union): \n",
    "    - [`dice_coeff`](#dice-coefficient): \n",
    "    - [`unet_model`](#u-net-model-definition): \n",
    "    - [`plot_losses`](#plot-model-losses): \n",
    "    - [`test_unet`](#test-trained-u-net): \n",
    "    - [`save_predicted_masks`](#save-predicted-masks): \n",
    "\n",
    "\n",
    "## Usage\n",
    "This notebook is not intended to be run individually. The public functions in this notebook should be imported into the `main.ipynb` using the `import-ipynb` package. The purpose of this notebook is to clearly separate and define each U-Net-related function that is called internally (in this notebook by one of the other functions) and each U-Net-related function that is called in `main.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages\n",
    "\n",
    "We first import the necessary packages used by the functions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from typing import Optional, Dict, List, Tuple, Any, Union\n",
    "\n",
    "# Optional line to suppress unnecessary tensorflow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras import layers, models, Model, backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Functions\n",
    "\n",
    "This section contains any internal, or private functions. These functions are ones that are called by other functions, and are not intended for use in any other manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function to get colors for the classes for display\n",
    "def _get_colors(num_colors: int, color_map: str) -> Dict[int, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates a dictionary of colors for each class.\n",
    "\n",
    "    Args:\n",
    "        num_colors (int): The number of colors to generate.\n",
    "        color_map (str): Matplotlib colormap.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, np.ndarray]: A dictionary where the key is the class index and the value is a numpy array representing the RGB colors.\n",
    "    \"\"\"\n",
    "    # Select the color map from matplotlib's library, and keep only the RGB color information\n",
    "    if color_map:\n",
    "        try:\n",
    "            colors = cm.get_cmap(color_map, num_colors)\n",
    "        # If the color map is not recognized in matplotlib's color map, warn the user and use the default \n",
    "        except ValueError:\n",
    "            warnings.warn(\n",
    "                f\"Unrecognized color map {color_map}.\\n\" \"Will use default 'viridis'.\\n\",\n",
    "                UserWarning,\n",
    "            )\n",
    "            colors = cm.get_cmap(\"viridis\", num_colors)\n",
    "\n",
    "    # If no colors are given, use the default\n",
    "    else:\n",
    "        colors = cm.get_cmap(\"viridis\", num_colors)\n",
    "\n",
    "    # Extract the RGB values from the colormap\n",
    "    colors = colors(np.arange(num_colors))[:, :3]\n",
    "\n",
    "    # Create a dictionary of class colors\n",
    "    class_colors = {idx: colors[idx] for idx in range(num_colors)}\n",
    "    return class_colors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function to get or assign class labels\n",
    "def _get_class_labels(\n",
    "    class_labels: Union[Dict[int, str], None], num_classes: int\n",
    ") -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Ensures the class labels dictionary is correctly set up. If class_labels is None,\n",
    "    generates a dictionary of class labels.\n",
    "\n",
    "    Args:\n",
    "        class_labels (Optional[Dict[int, str]]): An optional dictionary of class labels.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, str]: A dictionary where the key is the class index and the value is the class label as a string.\n",
    "    \"\"\"\n",
    "    # If class_labels is not provided, generate default labels based on the number of classes\n",
    "    if not class_labels:\n",
    "        num_labels = 2 if num_classes == 1 else num_classes\n",
    "        class_labels = {idx: str(idx) for idx in range(num_labels)}\n",
    "\n",
    "    # Handle the case where there is only one class label but two classes (binary classification)\n",
    "    elif len(class_labels) == 1 and num_classes == 2:\n",
    "        key, value = next(iter(class_labels.items()))\n",
    "        background_key = 1 if key == 0 else 0\n",
    "        class_labels[background_key] = \"Assigned Background\"\n",
    "\n",
    "    # If the number of class labels does not match the number of classes, reset the labels\n",
    "    elif len(class_labels) != num_classes and not (\n",
    "        len(class_labels) == 2 and num_classes == 1\n",
    "    ):\n",
    "        print(\n",
    "            f\"Number of class labels ({len(class_labels)}) does not match the number of classes ({num_classes}). Labels will be changed to class index numbers.\"\n",
    "        )\n",
    "        num_labels = 2 if num_classes == 1 else num_classes\n",
    "        class_labels = {idx: str(idx) for idx in range(num_labels)}\n",
    "\n",
    "    return class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Colored Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function to color the masks and the predicted masks based on the color map and class labels\n",
    "def _get_color_masks(\n",
    "    num_classes: int,\n",
    "    masks: np.ndarray,\n",
    "    predicted_masks: np.ndarray,\n",
    "    class_labels: Dict[int, str],\n",
    "    class_color_map: str,\n",
    ") -> Tuple[np.ndarray, np.ndarray, Dict[int, Dict[str, Union[str, np.ndarray]]]]:\n",
    "    \"\"\"\n",
    "    Colors the masks and predicted masks for visualization.\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): The number of classes.\n",
    "        masks (np.ndarray): The ground truth masks.\n",
    "        predicted_masks (np.ndarray): The predicted masks.\n",
    "        class_labels (Dict[int, str]): A dictionary where the key is the class index (int) and the value is a class label.\n",
    "        class_color_map (str): Matplotlib colormap.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, Dict[int, Dict[str, Union[str, np.ndarray]]]]: A tuple containing:\n",
    "            - colored_masks (np.ndarray): The colored ground truth masks.\n",
    "            - colored_preds (np.ndarray): The colored predicted masks.\n",
    "            - class_colors_and_labels (Dict[int, Dict[str, Union[str, np.ndarray]]]): A dictionary where the key is the class index and each class index contains a color and label.\n",
    "    \"\"\"\n",
    "    # Determine the number of colors needed based on the number of classes\n",
    "    if num_classes == 1:\n",
    "        num_colors = 2 # One color for background, one color for foreground\n",
    "    else:\n",
    "        num_colors = num_classes\n",
    "\n",
    "    # Get the colors for each class using the specified colormap\n",
    "    class_colors = _get_colors(num_colors, class_color_map)\n",
    "\n",
    "    # Create a dictionary to store the color and label for each class\n",
    "    class_colors_and_labels = {}\n",
    "    for key in class_colors:\n",
    "        class_colors_and_labels[key] = {\n",
    "            \"color\": class_colors[key],\n",
    "            \"label\": class_labels[key],\n",
    "        }\n",
    "\n",
    "    # Create a color map that can easily be applied to the masks and predictions\n",
    "    color_map = np.array(\n",
    "        [class_colors.get(color, [0, 0, 0]) for color in range(num_colors)],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Apply the color map to the ground truth masks and predicted masks\n",
    "    colored_masks = color_map[masks]\n",
    "    colored_preds = color_map[predicted_masks]\n",
    "\n",
    "    return colored_masks, colored_preds, class_colors_and_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Basic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function to compute some basic metrics that asses model performance on the test data. \n",
    "def _compute_basic_metrics(\n",
    "    masks: np.ndarray, predicted_masks: np.ndarray, metric_ave_method: str\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Computes basic metrics (precision, recall, and F1 score) for the given masks and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        masks (np.ndarray): The ground truth masks.\n",
    "        predicted_masks (np.ndarray): The predicted masks.\n",
    "        metric_ave_method (str): Averaging method to use in the metrics.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: A dictionary containing the precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    # Flatten the masks and predictions as necessary for the scikit-learn library metrics\n",
    "    masks = masks.flatten()\n",
    "    predicted_masks = predicted_masks.flatten()\n",
    "    # Precision: Calculates the precision, which is the ratio of correctly predicted positive observations to the total predicted positives. It is a measure of the accuracy of the positive predictions.\n",
    "    # Precision = true_positives / (true_positives + false_positives)\n",
    "    precision = precision_score(\n",
    "        masks, predicted_masks, zero_division=0, average=metric_ave_method\n",
    "    )\n",
    "    # Recall: Calculates the recall, also known as sensitivity or true positive rate, which is the ratio of correctly predicted positive observations to all the actual positives. It is a measure of how well the model can capture positive instances.\n",
    "    # Recall = true_positives / (true_positives + false_negatives)\n",
    "    recall = recall_score(\n",
    "        masks, predicted_masks, zero_division=0, average=metric_ave_method\n",
    "    )\n",
    "    # F1 Score: Calculates the F1 score, which is the weighted average of precision and recall. It considers both false positives and false negatives and is useful when you need a balance between precision and recall.\n",
    "    # F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    f1 = f1_score(masks, predicted_masks, zero_division=0, average=metric_ave_method)\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1 score\": f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal function to view the predictions based on the test data\n",
    "def _view_predictions(\n",
    "    images: np.ndarray,\n",
    "    colored_masks: np.ndarray,\n",
    "    colored_preds: np.ndarray,\n",
    "    image_names: List[str],\n",
    "    class_colors_and_labels: Dict[int, Dict[str, Union[str, np.ndarray]]],\n",
    "    display_count: int,\n",
    "    images_per_figure: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Displays the images, their masks, and the model predictions of the masks.\n",
    "\n",
    "    Args:\n",
    "        images (np.ndarray): The input images.\n",
    "        colored_masks (np.ndarray): The colored ground truth masks.\n",
    "        colored_preds (np.ndarray): The colored predicted masks.\n",
    "        image_names (List[str]): List of image names.\n",
    "        class_colors_and_labels (Dict[int, Dict[str, Union[str, np.ndarray]]]): A dictionary where the key is the class index and each class index contains a color and label.\n",
    "        display_count (int): The number of images to display.\n",
    "        images_per_figure (int): The number of images per figure.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything. It displays the figures.\n",
    "    \"\"\"\n",
    "    # Determine the number of images to display\n",
    "    img_cnt = min(display_count, len(images))\n",
    "    \n",
    "    # If image names are not provided, create names based on the number of images\n",
    "    if image_names is None:\n",
    "        image_names = [str(idx) for idx in range(len(images))]\n",
    "\n",
    "    # Create legend patches (labels) for each mask class\n",
    "    patches = [\n",
    "        mpatches.Patch(\n",
    "            color=class_colors_and_labels[idx][\"color\"],\n",
    "            label=class_colors_and_labels[idx][\"label\"],\n",
    "        )\n",
    "        for idx in class_colors_and_labels\n",
    "    ]\n",
    "\n",
    "    # Calculate the number of figures needed\n",
    "    num_figs = (img_cnt + images_per_figure - 1) // images_per_figure\n",
    "\n",
    "    # Loop over each figure\n",
    "    for fig_idx in range(num_figs):\n",
    "\n",
    "        # Determine the number of images in the current figure\n",
    "        img_in_fig = min(images_per_figure, img_cnt - fig_idx * images_per_figure)\n",
    "\n",
    "        # Create subplots for the current figure\n",
    "        fig, axes = plt.subplots(img_in_fig, 3, figsize=(10, 3 * img_in_fig))\n",
    "\n",
    "        # Ensure axes is a 2D array even if there's only one row\n",
    "        if img_in_fig == 1:\n",
    "            axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "        # Loop over each image to be included in the current figure\n",
    "        for idx in range(img_in_fig):\n",
    "            img_idx = (fig_idx * images_per_figure) + idx\n",
    "            if img_idx >= img_cnt:\n",
    "                break\n",
    "            \n",
    "            # Extract the image, mask, and predicted mask\n",
    "            image, mask, prediction = (\n",
    "                images[img_idx],\n",
    "                colored_masks[img_idx],\n",
    "                colored_preds[img_idx],\n",
    "            )\n",
    "\n",
    "            # Plot the image\n",
    "            ax_img, ax_mask, ax_pred = axes[idx]\n",
    "            ax_img.imshow(image)\n",
    "            ax_img.axis(\"off\")\n",
    "            ax_img.set_title(f\"Image {image_names[img_idx]}\")\n",
    "\n",
    "            # Plot the true mask\n",
    "            ax_mask.imshow(mask)\n",
    "            ax_mask.axis(\"off\")\n",
    "            ax_mask.set_title(f\"Mask {image_names[img_idx]}\")\n",
    "            \n",
    "            # Plot the predicted mask\n",
    "            ax_pred.imshow(prediction)\n",
    "            ax_pred.axis(\"off\")\n",
    "            ax_pred.set_title(f\"Pred. Mask {image_names[img_idx]}\")\n",
    "\n",
    "        # Add legend to the figure using the color labels\n",
    "        fig.legend(\n",
    "            handles=patches,\n",
    "            loc=\"upper right\",\n",
    "            bbox_to_anchor=(1, 1),\n",
    "            bbox_transform=fig.transFigure,\n",
    "        )\n",
    "        # Adjust layout and display the figure without blocking execution\n",
    "        plt.tight_layout()\n",
    "        plt.show(block=False)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Functions\n",
    "\n",
    "The functions in this section are public functions which can be called or passed outside this notebook, and are intended for use in the `main.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection Over Union "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric used when training the model. Intersection Over Union (IOU)\n",
    "def iou_metric(\n",
    "    true_masks: np.ndarray, predicted_masks: np.ndarray, smooth: float = 1e-8\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) metric for the given true and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        true_masks (np.ndarray): The ground truth masks.\n",
    "        predicted_masks (np.ndarray): The predicted masks.\n",
    "        smooth (float, optional): A small value to avoid division by zero. Default is 1e-8.\n",
    "\n",
    "    Returns:\n",
    "        float: The IoU metric.\n",
    "    \"\"\"\n",
    "    # Flatten the true and predicted masks to 1D arrays\n",
    "    true_masks = backend.flatten(true_masks)\n",
    "    predicted_masks = backend.flatten(predicted_masks)\n",
    "\n",
    "    # Calculate the intersection of the true and predicted masks\n",
    "    intersection = backend.sum(true_masks * predicted_masks)\n",
    "\n",
    "    # Calculate the union of the true and predicted masks\n",
    "    union = backend.sum(true_masks) + backend.sum(predicted_masks) - intersection\n",
    "\n",
    "    # Calculate the Intersection Over Union (IOU)\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric used when training the model. Dice Coefficient.\n",
    "def dice_coeff(\n",
    "    true_masks: np.ndarray, predicted_masks: np.ndarray, smooth: float = 1e-8\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Dice Coefficient for the given true and predicted masks.\n",
    "\n",
    "    Args:\n",
    "        true_masks (np.ndarray): The ground truth masks.\n",
    "        predicted_masks (np.ndarray): The predicted masks.\n",
    "        smooth (float, optional): A small value to avoid division by zero. Default is 1e-8.\n",
    "\n",
    "    Returns:\n",
    "        float: The Dice Coefficient.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Flatten the true and predicted masks to 1D arrays\n",
    "    true_masks = backend.flatten(true_masks)\n",
    "    predicted_masks = backend.flatten(predicted_masks)\n",
    "\n",
    "    # Calculate the intersection of the true and predicted masks\n",
    "    intersection = backend.sum(true_masks * predicted_masks)\n",
    "\n",
    "    # Calculate the Dice Coefficient\n",
    "    dice = (2.0 * intersection + smooth) / (\n",
    "        backend.sum(true_masks) + backend.sum(predicted_masks) + smooth\n",
    "    )\n",
    "    return dice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ot define teh actual U-Net model\n",
    "def unet_model(\n",
    "    input_shape: Tuple[int, int, int],\n",
    "    num_classes: int,\n",
    "    num_blocks: int = 4,\n",
    "    optimizer: str = \"adam\",\n",
    "    metrics: List[str] = [\"accuracy\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds a U-Net model for image segmentation.\n",
    "\n",
    "    Args:\n",
    "        input_shape (Tuple[int, int, int]): The shape of the input images (height, width, channels).\n",
    "        num_classes (int): The number of output classes for segmentation.\n",
    "        num_blocks (int, optional): The number of encode/decode blocks in the U-Net. Default is 4.\n",
    "        optimizer (str, optional): Optimization method to use for the model. The default is \"adam\".\n",
    "        metrics (List[str], optional): Optional metrics used in model training improvements. Default is [\"accuracy\"] .\n",
    "\n",
    "    Returns:\n",
    "        Model: A TensorFlow Keras Model representing the U-Net.\n",
    "    \"\"\"\n",
    "    # Create input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initialize components for subsequent encoder and decoder layers\n",
    "    encoder_layers = []\n",
    "    x = inputs  # updates at every layer\n",
    "    filters = 64  # Initial number of filters, updates at every layer block\n",
    "    \n",
    "    # For each encoder block create 3 layers: 2 ReLU convolution layers, and 1 MaxPooling layer. Also store the result from te 2 convolution layers for skipping when decoding.\n",
    "    for idx in range(num_blocks):\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        encoder_layers.append(x)  # Store the result for skip connections\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        filters *= 2 # Double the number of filters for the next block\n",
    "\n",
    "    # Bottleneck block: 2 ReLU convolution layers\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    # For each decoder block create 4 layers: 1 UpSampling, 1 Concatentation with the skipped encoder layer from the same level, and 2 ReLU convolution layers.\n",
    "    for idx in reversed(range(num_blocks)):\n",
    "        filters //= 2 # Halve the number of filters for the next block\n",
    "        x = layers.UpSampling2D(size=2)(x)\n",
    "        x = layers.concatenate([x, encoder_layers[idx]], axis=-1) # Concatenate with the corresponding encoder layer\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "    # Select the appropriate activation and loss functions based on the number of classes in the input data.\n",
    "    if num_classes == 1:\n",
    "        activation_fn = \"sigmoid\"\n",
    "        loss_fn = \"binary_crossentropy\"\n",
    "    else:\n",
    "        activation_fn = \"softmax\"\n",
    "        loss_fn = \"categorical_crossentropy\"\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(num_classes, 1, activation=activation_fn)(x)\n",
    "\n",
    "    # Create the model as tensorflow NN Model.\n",
    "    unet_model = models.Model(inputs, outputs)\n",
    "\n",
    "    # Compile the model with the desired optimizer, loss function, and metrics\n",
    "    unet_model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "    return unet_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Model Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ot plot the losses from the training process of the U-Net model\n",
    "def plot_losses(model_fit: Any) -> None:\n",
    "    \"\"\"\n",
    "    Plots the training and validation losses from the model fitting process.\n",
    "\n",
    "    Args:\n",
    "        model_fit (Any): The result of the model fitting process (e.g., the history object returned by `model.fit`).\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything. It plots the training and validation losses.\n",
    "    \"\"\"\n",
    "    # Create a new figure with specified size\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Plot the training loss\n",
    "    plt.plot(model_fit.history[\"loss\"], label=\"Train Loss\")\n",
    "    \n",
    "    # Plot the validation loss\n",
    "    plt.plot(model_fit.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "\n",
    "    # Set axes labels and limits\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "\n",
    "    # Set the title \n",
    "    plt.title(\"Training Loss vs. Validation Loss\")\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Adjust fit for neatest, and don't block execution with the plot \n",
    "    plt.tight_layout()\n",
    "    plt.show(block=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trained U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the U-Net model after training\n",
    "def test_unet(\n",
    "    model: Model,\n",
    "    images: np.ndarray,\n",
    "    masks: np.ndarray,\n",
    "    num_classes: int,\n",
    "    threshold: float = 0.5,\n",
    "    image_names: Optional[List[str]] = None,\n",
    "    class_labels: Optional[Dict[int, str]] = None,\n",
    "    class_color_map: Optional[str] = None,\n",
    "    display_figures: bool = True,\n",
    "    display_count: int = 3,\n",
    "    images_per_figure: int = 3,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Tests the U-Net model by plotting the predictions on a set of images and their corresponding masks.\n",
    "\n",
    "    Args:\n",
    "        model (Model): The U-Net model to be tested.\n",
    "        images (np.ndarray): The input images.\n",
    "        masks (np.ndarray): The ground truth masks.\n",
    "        num_classes (int): The number of classes.\n",
    "        threshold (float, optional): Threshold to  use if the number of classes is 1 (binary). Default is 0.5.\n",
    "        image_names (Optional[List[str]], optional): List of image names. Default is None.\n",
    "        class_labels (Optional[Dict[int, str]], optional): A dictionary where the key is the class index and the value is a the class label. Default is None.\n",
    "        display_figures (bool, optional): Whether to display the figures. Default is True.\n",
    "        class_color_map (Optional[str]): Matplotlib colormap. Default is viridis.\n",
    "        display_count (int, optional): The number of images to display. Default is 3.\n",
    "        images_per_figure (int, optional): The number of images per figure. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The predicted masks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Predict masks using the U-Net model\n",
    "    predicted_masks = model.predict(images)\n",
    "\n",
    "    # Process predicted masks based on the number of classes\n",
    "    if num_classes == 1:\n",
    "        # Converting the predicted masks and masks back to the correct format for plotting and for performance metrics\n",
    "        predicted_masks = (predicted_masks[..., 0] > threshold).astype(np.uint8)\n",
    "        masks = (masks > threshold).astype(np.uint8)\n",
    "\n",
    "        # Setting the method to be used in the metrics based on the number of classes\n",
    "        metric_ave_method = \"binary\" \n",
    "    else:\n",
    "        # Converting the predicted masks and masks back to the correct format for plotting and for performance metrics\n",
    "        predicted_masks = np.argmax(predicted_masks, axis=-1).astype(np.uint8)\n",
    "        masks = np.argmax(masks, axis=-1).astype(np.uint8)\n",
    "        \n",
    "        # Setting the method to be used in the metrics based on the number of classes\n",
    "        metric_ave_method = None \n",
    "\n",
    "     # Get class labels, ensuring they are defined for potential figure legends\n",
    "    class_labels = _get_class_labels(class_labels, num_classes)\n",
    "\n",
    "    # Compute metrics for the predicted masks\n",
    "    metrics = _compute_basic_metrics(masks, predicted_masks, metric_ave_method)\n",
    "    print(\"Metrics based on test data:\\n\")\n",
    "    \n",
    "    # If multiple classes then print metrics for each class in the predicted masks\n",
    "    if metric_ave_method != \"binary\":\n",
    "        for idx in range(num_classes):\n",
    "\n",
    "            # Verify that there are metrics for the given class index\n",
    "            if 0 <= idx < len(metrics[\"precision\"]):\n",
    "                print(f\"Class {class_labels[idx]} Individual Metrics:\")\n",
    "                print(f\"Precision: {metrics['precision'][idx]}\")\n",
    "                print(f\"Recall: {metrics['recall'][idx]}\")\n",
    "                print(f\"F1 Score: {metrics['f1 score'][idx]}\\n\")\n",
    "            else:\n",
    "                print(f\"Class {class_labels[idx]} Individual Metrics:\")\n",
    "                print(\n",
    "                    f\"Class {class_labels[idx]} not found in predicted masks. No metrics available.\"\n",
    "                )\n",
    "\n",
    "    # Else if only a background and foreground class (binary), print the metrics for the foreground\n",
    "    else:\n",
    "        print(f\"Precision: {metrics['precision']}\\n\")\n",
    "        print(f\"Recall: {metrics['recall']}\\n\")\n",
    "        print(f\"F1 Score: {metrics['f1 score']}\\n\")\n",
    "\n",
    "    # Display figures if the flag is set to True\n",
    "    if display_figures:\n",
    "        # Get the labels and colored masks\n",
    "        colored_masks, colored_preds, class_colors_and_labels = _get_color_masks(\n",
    "            num_classes, masks, predicted_masks, class_labels, class_color_map\n",
    "        )\n",
    "\n",
    "        # Display the figures that show the image, mask, and prediction\n",
    "        _view_predictions(\n",
    "            images,\n",
    "            colored_masks,\n",
    "            colored_preds,\n",
    "            image_names,\n",
    "            class_colors_and_labels,\n",
    "            display_count,\n",
    "            images_per_figure,\n",
    "        )\n",
    "\n",
    "    return predicted_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Predicted Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predicted_masks(\n",
    "    predicted_masks: np.ndarray,\n",
    "    output_dir: str,\n",
    "    mask_names: Optional[List[str]] = None,\n",
    "    file_ext: str = \"tif\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Saves the predicted masks to the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        predicted_masks (np.ndarray): Array containing the predicted masks.\n",
    "        output_dir (str): Path to the directory where the masks will be saved.\n",
    "        mask_names (Optional[List[str]], optional): List of mask names to save. If None, all masks will be saved. Default is None.\n",
    "        file_ext (str, optional): File extension for the saved masks. Default is \"tif\".\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return anything.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Normalize file extension to lowercase and handle \"tif\" as \"tiff\"\n",
    "    file_ext = file_ext.strip().lower()\n",
    "    if file_ext == \"tif\":\n",
    "        file_ext = \"tiff\"\n",
    "\n",
    "    # If no mask names are provided, generate default names based on indices\n",
    "    if not mask_names:\n",
    "        mask_names = [str(idx) for idx in range(len(predicted_masks))]\n",
    "\n",
    "    # Save each predicted mask with the corresponding name and file extension\n",
    "    for predicted_mask, mask_name in zip(predicted_masks, mask_names):\n",
    "        file_name = f\"pred_{mask_name}.{file_ext}\"\n",
    "        Image.fromarray(predicted_mask).save(\n",
    "            output_dir / file_name, format=file_ext.upper()\n",
    "        )\n",
    "    print(f\"Data saved in {output_dir}.\")\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
